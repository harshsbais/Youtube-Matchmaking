{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd057ca423a0bff2dc112e8b1ccea5fe7c1570b7d0eadbb4b42d72e4c4cd55ac19b",
   "display_name": "Python 3.7.9 64-bit ('yt': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo as mongo\n",
    "import json\n",
    "import shlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class youtube:\n",
    "    def __init__(self, db):\n",
    "        self.yt=self.start_api(api_key=mongo_srv)\n",
    "        self.db=db\n",
    "    def start_api(self, api_key=yt_key):\n",
    "        api_service_name = \"youtube\"\n",
    "        api_version = \"v3\" \n",
    "        yt = googleapiclient.discovery.build(api_service_name, api_version, developerKey=api_key)\n",
    "        return yt\n",
    "    def channel_info(self, ids):\n",
    "        infos = []\n",
    "        info = self.yt.channels().list(part=[\"brandingSettings\", \"id\", \"statistics\", \"topicDetails\", \"snippet\"], fields=\"items\", id=ids)\n",
    "        info = info.execute()\n",
    "        infos += info[\"items\"]\n",
    "        response = []\n",
    "        for json in infos:\n",
    "            response.append(self.clean_channel_json(json))\n",
    "        return response\n",
    "    def clean_channel_json(self, json):\n",
    "        new_json={}\n",
    "        new_json[\"id\"]=json[\"id\"]\n",
    "        new_json[\"collab\"]=False\n",
    "        new_json[\"title\"]=json[\"brandingSettings\"][\"channel\"][\"title\"]\n",
    "        new_json[\"description\"]=json[\"brandingSettings\"][\"channel\"].get(\"description\")\n",
    "        new_json[\"keywords\"]=json[\"brandingSettings\"][\"channel\"].get(\"keywords\")\n",
    "        new_json[\"country\"]=json[\"brandingSettings\"][\"channel\"].get(\"country\")\n",
    "        new_json[\"viewCount\"]=int(json[\"statistics\"].get(\"viewCount\", \"0\"))\n",
    "        new_json[\"subscriberCount\"]=int(json[\"statistics\"].get(\"subscriberCount\",\"0\"))\n",
    "        new_json[\"videoCount\"]=int(json[\"statistics\"].get(\"videoCount\",\"0\"))\n",
    "        new_json[\"image\"]=json[\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]\n",
    "        new_json[\"topics\"]=[]\n",
    "        if json.get(\"topicDetails\") != None:\n",
    "            json_topics=json[\"topicDetails\"].get(\"topicCategories\",[])\n",
    "            for i in range(len(json_topics)):\n",
    "                new_json[\"topics\"].append(json_topics[i].replace(\"https://en.wikipedia.org/wiki/\",\"\"))\n",
    "        return new_json\n",
    "    def channel_to_database(self, json):\n",
    "        for channel in json:\n",
    "            self.db.channels.update_one({\"title\":channel[\"title\"]}, {\"$set\": channel}, upsert=True)\n",
    "        return len(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mongo.MongoClient(mongo_srv)\n",
    "db = client.matchmaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x2510795df08>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "db.channels.update_many({}, {\"$set\":{\"collab\":False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = youtube(db)"
   ]
  },
  {
   "source": [
    "## Input information into the database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt.channel_to_database(yt.channel_info(\"Fighting Games\", results=500))"
   ]
  },
  {
   "source": [
    "## Updating information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an example were wu updated the channel's profile image\n",
    "\n",
    "for channel in yt.db.channels.find({}):\n",
    "\n",
    "    info = yt.yt.channels().list(part=\"snippet\",id=channel[\"id\"])\n",
    "    info = info.execute()\n",
    "    if info.get(\"items\")==None:\n",
    "        continue\n",
    "    info = info[\"items\"][0]\n",
    "    yt.db.channels.update_one({\"id\":info[\"id\"]},{\"$set\": {\"image\": info[\"snippet\"][\"thumbnails\"][\"high\"][\"url\"]}})"
   ]
  },
  {
   "source": [
    "## Setting up keywords that will be used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create our dictionary of keywords\n",
    "\n",
    "keywords={}\n",
    "for channel in yt.db.channels.find({}):\n",
    "    if channel[\"keywords\"]!= None:\n",
    "        for keyword in shlex.split(channel[\"keywords\"].replace(\"'\", \"\")):\n",
    "            keyword=keyword.lower()\n",
    "            keywords[keyword]=keywords.get(keyword, 0)+1\n",
    "    if channel[\"topics\"]!=None:\n",
    "        for keyword in channel[\"topics\"]:\n",
    "            keyword=keyword.replace(\"_\",\" \")\n",
    "            keyword=keyword.lower()\n",
    "            keywords[keyword]=keywords.get(keyword, 0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for channel in yt.db.channels.find({}):\n",
    "    if channel[\"description\"]!= None:\n",
    "        for keyword in shlex.split(channel[\"description\"].replace(\"'\", \"\").replace(\"/n\", \"\").replace('\"', \"\")):\n",
    "            keyword=keyword.lower()\n",
    "            if keyword in keywords.keys():\n",
    "                keywords[keyword]+=1\n",
    "    if channel[\"title\"]!= None:\n",
    "        for keyword in shlex.split(channel[\"title\"].replace(\"'\", \"\").replace(\"/n\", \"\").replace('\"', \"\")):\n",
    "            keyword=keyword.lower()\n",
    "            if keyword in keywords.keys():\n",
    "                keywords[keyword]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution={}\n",
    "for keyword in keywords:\n",
    "    distribution[keywords[keyword]]=distribution.get(keywords[keyword],0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "top_keywords=[]\n",
    "for keyword in keywords.keys():\n",
    "    if keywords[keyword]>=4:   #Numbers chosen so that words appear in reasonable amount of channels not too few\n",
    "        top_keywords.append(keyword)\n",
    "len(top_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top_keywords.json\", \"w\") as json_file:\n",
    "    json.dump(top_keywords, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords={}\n",
    "for channel in yt.db.channels.find({}):\n",
    "    channel_top_keywords=set()\n",
    "    if channel[\"keywords\"]!= None:\n",
    "        for keyword in shlex.split(channel[\"keywords\"].replace(\"'\", \"\")):\n",
    "            keyword=keyword.lower()\n",
    "            if keyword in top_keywords:\n",
    "                channel_top_keywords.add(keyword)\n",
    "    if channel[\"description\"]!= None:\n",
    "        for keyword in shlex.split(channel[\"description\"].replace(\"'\", \"\").replace(\"/n\", \"\").replace('\"', \"\")):\n",
    "            keyword=keyword.lower()\n",
    "            if keyword in top_keywords:\n",
    "                channel_top_keywords.add(keyword)\n",
    "    if channel[\"topics\"]!=None:\n",
    "        for keyword in channel[\"topics\"]:\n",
    "            keyword=keyword.replace(\"_\",\" \")\n",
    "            keyword=keyword.lower()\n",
    "            if keyword in top_keywords:\n",
    "                channel_top_keywords.add(keyword)\n",
    "    if channel[\"title\"]!= None:\n",
    "        for keyword in shlex.split(channel[\"title\"].replace(\"'\", \"\").replace(\"/n\", \"\").replace('\"', \"\")):\n",
    "            keyword=keyword.lower()\n",
    "            if keyword in top_keywords:\n",
    "                channel_top_keywords.add(keyword)\n",
    "    channel_top_keywords=list(channel_top_keywords)\n",
    "    yt.db.channels.update_one({\"title\":channel[\"title\"]},{\"$set\":{\"top_keywords\":channel_top_keywords}})"
   ]
  },
  {
   "source": [
    "# Have vector representing each channel."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-11-c2fdeb822269>:12: RuntimeWarning: invalid value encountered in true_divide\n  vector=vector/len(keywords)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "for channel in db.channels.find({}):\n",
    "    word_vectors = gensim.models.KeyedVectors.load('word_vectors.kv')\n",
    "    keywords=channel[\"top_keywords\"]\n",
    "    vector=np.array([0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            vector+=word_vectors.get_vector(keyword)\n",
    "        except:\n",
    "            pass\n",
    "    vector=vector/len(keywords)\n",
    "    vector=list(vector)\n",
    "    db.channels.update_one({\"title\":channel[\"title\"]},{\"$set\":{\"vector\":vector}})"
   ]
  },
  {
   "source": [
    "## Getting approximate timezone data based on country"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raw_timezones.json\", \"r\") as json_file:\n",
    "    raw_timezones=json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "timezones={}\n",
    "for timezone in raw_timezones:\n",
    "    timezones[timezone[\"countryCode\"]]=int(timezone[\"locales\"][0][\"name\"][4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"timezones.json\", \"w\") as json_file:\n",
    "    json.dump(timezones, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in db.channels.find({}):\n",
    "    db.channels.update_one({\"title\":channel[\"title\"]},{\"$set\":{\"timezone\":timezones.get(channel.get(\"country\"),None)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}